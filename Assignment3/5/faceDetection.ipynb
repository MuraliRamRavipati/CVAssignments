{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2\r\n",
    "import glob\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from scipy.signal import fftconvolve,convolve2d\r\n",
    "import math\r\n",
    "from PIL import Image\r\n",
    "import numpy as np \r\n",
    "import copy\r\n",
    "from collections import deque\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Multiple Face Detection using Haar-Cascade\r\n",
    "\r\n",
    "face_detector_model = cv2.CascadeClassifier('facefrontal.xml')\r\n",
    "\r\n",
    "# reading the input image now\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "while cap.isOpened():\r\n",
    "    _, frame = cap.read()\r\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
    "    faces = face_detector_model.detectMultiScale(gray,1.1, 4 )\r\n",
    "    for (x,y, w, h) in faces:\r\n",
    "        cv2.putText(frame, \"Person1\", (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\r\n",
    "        cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,255,0),thickness =  3)\r\n",
    "        roi_gray = gray[y:y+h,x:x+w]\r\n",
    "        roi_color = frame[y:y+h, x:x+w]\r\n",
    "        cv2.imshow(\"window\", frame)\r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- These are the values thhat are calcullated manually based on the 20 different images taken"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy\r\n",
    "- Accuracy=(TP+FP)/(TP+TN+FP+FN)\r\n",
    "- Accuracy=18/20=0.90"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Precision\r\n",
    "- Presion=TP/(TP+FP)\r\n",
    "- Precision=13/18=0.72\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recall\r\n",
    "- Recall=TP/(TP+FN)\r\n",
    "- Recall=10/11=0.91"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Intersection over Union\r\n",
    "- IOU=(area of overlap)/(area of union)\r\n",
    "- IOU=41/58=0.71\r\n",
    "- this is for one image(41 is area of overlap and 58 is area of union)\r\n",
    "- These are approximate values"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}